{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3e6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Config\n",
    "BASE_DIR = os.getcwd()  # this gets /.../ml-project-intro/models\n",
    "data_dir = os.path.abspath(os.path.join(BASE_DIR, '..', 'data'))        # go one level up and into data/\n",
    "data_dir = os.path.abspath(data_dir) #Normalize the path (resolve '..' correctly)\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'training')\n",
    "test_query_dir = os.path.join(data_dir,  'test', 'query')\n",
    "test_gallery_dir = os.path.join(data_dir, 'test', 'gallery')\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a91a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'c:\\\\Users\\\\ab\\\\Documents\\\\SARA\\\\Semester 2\\\\Intro Machine Learning\\\\ml-project-intro\\\\data\\\\training'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.path.exists(train_dir))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# will list subfolders/classes for training set\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.listdir(test_query_dir))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Impossibile trovare il percorso specificato: 'c:\\\\Users\\\\ab\\\\Documents\\\\SARA\\\\Semester 2\\\\Intro Machine Learning\\\\ml-project-intro\\\\data\\\\training'"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(train_dir))\n",
    "print(os.listdir(train_dir))  # will list subfolders/classes for training set\n",
    "print(os.listdir(test_query_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ac7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDatasetWithoutLabels(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name  # returning image and filename (no label)\n",
    "\n",
    "import os\n",
    "\n",
    "class ImageDatasetWithoutLabels(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(folder)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_files[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "# For training data (has subfolders/classes)\n",
    "train_dataset = datasets.ImageFolder(train_dir, data_transforms['train'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# For query data (NO subfolders/classes)\n",
    "query_dataset = ImageDatasetWithoutLabels(test_query_dir, transform=data_transforms['test'])\n",
    "query_loader = DataLoader(query_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# For gallery data (depends on structure)\n",
    "# Option 1: If gallery has subfolders/classes\n",
    "gallery_dataset = ImageDatasetWithoutLabels(test_gallery_dir, data_transforms['test'])\n",
    "gallery_loader = DataLoader(gallery_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def get_test_loader(dir_path):\n",
    "    dataset = datasets.ImageFolder(dir_path, data_transforms['test'])\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "query_dataset = ImageDatasetWithoutLabels(test_query_dir, transform=data_transforms['test'])\n",
    "query_loader = DataLoader(query_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(pretrained=True, feature_extract=True):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "    if feature_extract:\n",
    "        # For feature extraction, keep the backbone and remove the classification head\n",
    "        model.fc = nn.Identity()\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=20, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {running_loss / len(dataloader):.4f}\")\n",
    "\n",
    "def fine_tune_model(model, num_classes):\n",
    "    # Check if model.fc is a Sequential block or a single Linear layer\n",
    "    if isinstance(model.fc, nn.Sequential):\n",
    "        num_features = model.fc[0].in_features  # Extract from first layer in Sequential\n",
    "    else:\n",
    "        num_features = model.fc.in_features\n",
    "\n",
    "    # Replace with a new Sequential block for classification\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, loader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.vstack(features)\n",
    "\n",
    "def calculate_similarity(query_features, gallery_features):\n",
    "    similarities = cosine_similarity(query_features, gallery_features)\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(dataloader):\n",
    "    all_images = []\n",
    "    for images, _ in dataloader:\n",
    "        all_images.append(images.cpu())\n",
    "    return torch.cat(all_images, dim=0)\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return (img_tensor * std + mean).clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(similarities, k=10):\n",
    "    correct = 0\n",
    "    for i, query_sim in enumerate(similarities):\n",
    "        top_k_indices = np.argsort(query_sim)[-k:][::-1]\n",
    "        if i in top_k_indices:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(similarities)\n",
    "    print(f\"Top-{k} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def visualize_retrieved_images(query_loader, gallery_loader, similarities, k=10):\n",
    "    query_images = get_all_images(query_loader)\n",
    "    gallery_images = get_all_images(gallery_loader)\n",
    "\n",
    "    for i, query_sim in enumerate(similarities):\n",
    "        top_k_indices = np.argsort(query_sim)[-k:][::-1]\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        plt.subplot(1, k + 1, 1)\n",
    "        plt.imshow(denormalize(query_images[i]).permute(1, 2, 0))\n",
    "        plt.title(\"Query\")\n",
    "        plt.axis('off')\n",
    "        for j, idx in enumerate(top_k_indices):\n",
    "            plt.subplot(1, k + 1, j + 2)\n",
    "            plt.imshow(denormalize(gallery_images[idx]).permute(1, 2, 0))\n",
    "            plt.title(f\"Top {j+1}\")\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2be4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune model with classification head\n",
    "model = initialize_model(pretrained=True, feature_extract=False)\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = fine_tune_model(model, num_classes=num_classes)\n",
    "train_model(model, train_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "# Prepare model for feature extraction by removing classification head\n",
    "model.fc = nn.Identity()\n",
    "\n",
    "# Extract features for query and gallery images\n",
    "query_features = extract_features(model, query_loader)\n",
    "gallery_features = extract_features(model, gallery_loader)\n",
    "\n",
    "\n",
    "# Calculate similarity and evaluate\n",
    "similarities = calculate_similarity(query_features, gallery_features)\n",
    "calculate_accuracy(similarities, k=10)\n",
    "visualize_retrieved_images(query_loader, gallery_loader, similarities, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f919cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    WRITES JSON FILE\n",
    "#  Calculate similarity and evaluate\n",
    "similarities = calculate_similarity(query_features, gallery_features)\n",
    "\n",
    "# Get top-K indices for each query (sorted by similarity)\n",
    "K = 10\n",
    "I = np.argsort(similarities, axis=1)[:, -K:][:, ::-1]\n",
    "\n",
    "# Extract paths from datasets\n",
    "# Extract paths from datasets\n",
    "query_paths = [os.path.join(test_query_dir, name) for name in query_dataset.image_files]\n",
    "gallery_paths = [os.path.join(test_gallery_dir, name) for name in gallery_dataset.image_files]\n",
    "\n",
    "\n",
    "# Write JSON file in expected format\n",
    "submission = []\n",
    "for qi, qpath in enumerate(query_paths):\n",
    "    qname = os.path.basename(qpath)\n",
    "    retrieved = [os.path.basename(gallery_paths[i]) for i in I[qi]]\n",
    "    submission.append({\n",
    "        \"filename\": qname,\n",
    "        \"samples\": retrieved\n",
    "    })\n",
    "\n",
    "# Set output path: ../submission/sub_resnet2.json\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "out_path = os.path.join(base_dir, \"submissions\", \"sub_resnet2.json\")\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(submission, f, indent=2)\n",
    "\n",
    "print(f\"Done! {len(submission)} queries written to {out_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
