{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d3e6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Config\n",
    "BASE_DIR = os.getcwd()  # this gets /.../ml-project-intro/models\n",
    "data_dir = os.path.abspath(os.path.join(BASE_DIR, '..', 'data'))        # go one level up and into data/\n",
    "data_dir = os.path.abspath(data_dir) #Normalize the path (resolve '..' correctly)\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'training')\n",
    "test_query_dir = os.path.join(data_dir,  'test', 'query')\n",
    "test_gallery_dir = os.path.join(data_dir, 'test', 'gallery')\n",
    "\n",
    "fine_tune = True  # Set to False to skip training and only extract features\n",
    "resnet_version = 'resnet101'  # Change to: 'resnet18', 'resnet34', 'resnet50', or 'resnet101'\n",
    "k=10\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a91a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.path.exists(train_dir))\n",
    "# print(os.listdir(train_dir))  # will list subfolders/classes for training set\n",
    "# print(os.listdir(test_query_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04ac7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDatasetWithoutLabels(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name  # returning image and filename (no label)\n",
    "\n",
    "import os\n",
    "\n",
    "class ImageDatasetWithoutLabels(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(folder)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.folder, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.image_files[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a76fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "# For training data (has subfolders/classes)\n",
    "train_dataset = datasets.ImageFolder(train_dir, data_transforms['train'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# For query data (NO subfolders/classes)\n",
    "query_dataset = ImageDatasetWithoutLabels(test_query_dir, transform=data_transforms['test'])\n",
    "query_loader = DataLoader(query_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# For gallery data (depends on structure)\n",
    "# Option 1: If gallery has subfolders/classes\n",
    "gallery_dataset = ImageDatasetWithoutLabels(test_gallery_dir, data_transforms['test'])\n",
    "gallery_loader = DataLoader(gallery_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def get_test_loader(dir_path):\n",
    "    dataset = datasets.ImageFolder(dir_path, data_transforms['test'])\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "query_dataset = ImageDatasetWithoutLabels(test_query_dir, transform=data_transforms['test'])\n",
    "query_loader = DataLoader(query_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7878e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(resnet_version, pretrained=True, feature_extract=True):\n",
    "    model_fn = getattr(models, resnet_version)\n",
    "    model = model_fn(pretrained=pretrained)\n",
    "\n",
    "    if feature_extract:\n",
    "        # For feature extraction, keep the backbone and remove the classification head\n",
    "        model.fc = nn.Identity()\n",
    "\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19db1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=num_epochs, learning_rate=learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    final_loss = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        final_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {final_loss:.4f}\")\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def fine_tune_model(model, num_classes):\n",
    "    # Safely extract in_features from Linear layer\n",
    "    if isinstance(model.fc, nn.Sequential):\n",
    "        # Search for the first Linear layer in the Sequential block\n",
    "        for layer in model.fc:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                num_features = layer.in_features\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\"No Linear layer found in model.fc Sequential block.\")\n",
    "    elif isinstance(model.fc, nn.Linear):\n",
    "        num_features = model.fc.in_features\n",
    "    else:\n",
    "        raise TypeError(\"model.fc must be either nn.Linear or nn.Sequential\")\n",
    "\n",
    "    # Replace with a new Sequential block for classification\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(512, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfea4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, loader):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.vstack(features)\n",
    "\n",
    "def calculate_similarity(query_features, gallery_features):\n",
    "    similarities = cosine_similarity(query_features, gallery_features)\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f84d935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(dataloader):\n",
    "    all_images = []\n",
    "    for images, _ in dataloader:\n",
    "        all_images.append(images.cpu())\n",
    "    return torch.cat(all_images, dim=0)\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return (img_tensor * std + mean).clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2dbd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(similarities, k):\n",
    "    correct = 0\n",
    "    for i, query_sim in enumerate(similarities):\n",
    "        top_k_indices = np.argsort(query_sim)[-k:][::-1]\n",
    "        if i in top_k_indices:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(similarities)\n",
    "    print(f\"Top-{k} Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def visualize_retrieved_images(query_loader, gallery_loader, similarities, k):\n",
    "    query_images = get_all_images(query_loader)\n",
    "    gallery_images = get_all_images(gallery_loader)\n",
    "\n",
    "    for i, query_sim in enumerate(similarities):\n",
    "        top_k_indices = np.argsort(query_sim)[-k:][::-1]\n",
    "        plt.figure(figsize=(10, 2))\n",
    "        plt.subplot(1, k + 1, 1)\n",
    "        plt.imshow(denormalize(query_images[i]).permute(1, 2, 0))\n",
    "        plt.title(\"Query\")\n",
    "        plt.axis('off')\n",
    "        for j, idx in enumerate(top_k_indices):\n",
    "            plt.subplot(1, k + 1, j + 2)\n",
    "            plt.imshow(denormalize(gallery_images[idx]).permute(1, 2, 0))\n",
    "            plt.title(f\"Top {j+1}\")\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d2be4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fine-tune model with classification head\n",
    "# model = initialize_model(resnet_version, pretrained=True, feature_extract= not fine_tune)\n",
    "# if fine_tune:\n",
    "#     num_classes = len(train_dataset.classes)\n",
    "#     model = fine_tune_model(model, num_classes=num_classes)\n",
    "#     train_model(model, train_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "# else:\n",
    "#     # print(\"Skipping training, using pretrained model for feature extraction.\")\n",
    "#     # Prepare model for feature extraction by removing classification head\n",
    "#     model.fc = nn.Identity()\n",
    "\n",
    "# # Extract features for query and gallery images\n",
    "# query_features = extract_features(model, query_loader)\n",
    "# gallery_features = extract_features(model, gallery_loader)\n",
    "\n",
    "\n",
    "# # Calculate similarity and evaluate\n",
    "# similarities = calculate_similarity(query_features, gallery_features)\n",
    "# calculate_accuracy(similarities, k)\n",
    "# visualize_retrieved_images(query_loader, gallery_loader, similarities, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79fbd334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_metrics_json(\n",
    "    model_name,\n",
    "    top_k_accuracy,\n",
    "    batch_size,\n",
    "    is_finetuned,\n",
    "    num_classes=None,\n",
    "    runtime=None,\n",
    "    loss_function=\"CrossEntropyLoss\",\n",
    "    num_epochs=None,\n",
    "    final_loss=None\n",
    "):\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    results_dir = os.path.join(project_root, \"results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    out_path = os.path.join(results_dir, f\"{model_name}_metrics_{timestamp}.json\")\n",
    "\n",
    "    metrics = {\n",
    "        \"model_name\": model_name,\n",
    "        \"run_id\": timestamp,\n",
    "        \"top_k\": 10,\n",
    "        \"top_k_accuracy\": round(top_k_accuracy, 4),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"is_finetuned\": is_finetuned,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"runtime_seconds\": round(runtime, 2) if runtime else None,\n",
    "        \"loss_function\": loss_function,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"final_train_loss\": round(final_loss, 4) if final_loss is not None else None\n",
    "    }\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    print(f\"üìÅ Metrics saved to: {os.path.abspath(out_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f919cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MyPc\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MyPc\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 0.7159\n",
      "Epoch 2/5 - Loss: 1.3745\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. Initialize model\n",
    "model = initialize_model(resnet_version, pretrained=True, feature_extract=not fine_tune)\n",
    "\n",
    "# 2. Optional fine-tuning\n",
    "if fine_tune:\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    model = fine_tune_model(model, num_classes=num_classes)\n",
    "    final_loss = train_model(model, train_loader, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "else:\n",
    "    model.fc = nn.Identity()\n",
    "    final_loss = None  # No training, no loss\n",
    "\n",
    "\n",
    "# 3. Extract features\n",
    "query_features = extract_features(model, query_loader)\n",
    "gallery_features = extract_features(model, gallery_loader)\n",
    "\n",
    "# 4. Compute similarities and top-k indices\n",
    "similarities = calculate_similarity(query_features, gallery_features)\n",
    "I = np.argsort(similarities, axis=1)[:, -k:][:, ::-1]\n",
    "\n",
    "# 5. Get image paths\n",
    "query_paths = [os.path.join(test_query_dir, name) for name in query_dataset.image_files]\n",
    "gallery_paths = [os.path.join(test_gallery_dir, name) for name in gallery_dataset.image_files]\n",
    "\n",
    "# 6. Build submission format\n",
    "submission = []\n",
    "for qi, qpath in enumerate(query_paths):\n",
    "    qname = os.path.basename(qpath)\n",
    "    retrieved = [os.path.basename(gallery_paths[i]) for i in I[qi]]\n",
    "    submission.append({\n",
    "        \"filename\": qname,\n",
    "        \"samples\": retrieved\n",
    "    })\n",
    "\n",
    "# 7. Write JSON submission\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sub_dir = os.path.join(base_dir, \"submissions\")\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "out_path = os.path.join(sub_dir, f\"sub_{resnet_version}.json\")\n",
    "\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(submission, f, indent=2)\n",
    "\n",
    "print(f\"Done! {len(submission)} queries written to: {out_path}\")\n",
    "\n",
    "# 8. Evaluate accuracy\n",
    "top_k_acc = calculate_accuracy(similarities, k)\n",
    "\n",
    "# 9. Save metrics\n",
    "runtime = time.time() - start_time\n",
    "save_metrics_json(\n",
    "    model_name=resnet_version,\n",
    "    top_k_accuracy=top_k_acc,\n",
    "    batch_size=batch_size,\n",
    "    is_finetuned=fine_tune,\n",
    "    num_classes=len(train_dataset.classes),\n",
    "    runtime=runtime,\n",
    "    loss_function=\"CrossEntropyLoss\",  # fisso, se usi sempre questo\n",
    "    num_epochs=num_epochs,\n",
    "    final_loss=final_loss\n",
    ")\n",
    "\n",
    "\n",
    "# 10. Optional: Visualize retrieval results\n",
    "visualize_retrieved_images(query_loader, gallery_loader, similarities, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
