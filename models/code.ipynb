{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import sklearn\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import os\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "#test for get data\n",
    "\n",
    "root = os.path.join(os.path.dirname(__file__), '..', 'data')\n",
    "root_dir_train = os.path.join(root, 'training')\n",
    "root_dir_test  = os.path.join(root, 'test')\n",
    "\n",
    "\n",
    "def get_data(batch_size, test_batch_size=16, num_workers=2, mean=None, std=None, num_train_samples=None):\n",
    "    # for small size we can use 16 or 32 \n",
    "    # num_workers is the number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process. We can use 1 or 2 because we have a small size.\n",
    "\n",
    "    # Compute mean and standard deviation on training set if not given\n",
    "    target_size = (224, 224)\n",
    "    if mean is None or std is None:\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((target_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        train_data = ImageFolder(root_dir_train, transform=transform)\n",
    "        #loading images organized by “one folder per class\"\n",
    "        #Builds a list of (image_path, class_index) pairs\n",
    "\n",
    "        images = torch.stack([image for image, _ in train_data], dim=0)\n",
    "        #dimension 0 because we want to stack the images in a batch. \n",
    "        mean = torch.mean(images)\n",
    "        std = torch.std(images)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((target_size)),\n",
    "        transforms.Normalize(mean=[mean], std=[std])\n",
    "    ])\n",
    "\n",
    "    # Load data\n",
    "    train_data = ImageFolder(root_dir_train, transform=transform)    \n",
    "    test_data = ImageFolder(root_dir_test, transform=transform)\n",
    "\n",
    "    # Create train and validation splits\n",
    "    num_samples = len(train_data)\n",
    "    training_samples = int(num_samples * 0.7 + 1) if num_train_samples is None else num_train_samples\n",
    "    validation_samples = num_samples - training_samples\n",
    "    training_data, validation_data = torch.utils.data.random_split(train_data, [training_samples, validation_samples])\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_loader = DataLoader(training_data, batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader =DataLoader(validation_data, test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_data, test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "#main guard — prevents recursive spawning on Windows\n",
    "if __name__ == \"__main__\":\n",
    "    from multiprocessing import freeze_support\n",
    "    freeze_support()            # optional, silences a Windows warning\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_data(16)\n",
    "\n",
    "    i = iter(train_loader)\n",
    "    a = next(i)\n",
    "    for t in a:\n",
    "        print(t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntroML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
